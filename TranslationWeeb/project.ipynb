{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # install these dependencies and then comment them out\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download ja_core_news_md\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "cuda = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(cuda[0], enable=True)\n",
    "\n",
    "root_folder='.'\n",
    "data_folder_name='datafiles'\n",
    "train_filename='standford_raw'\n",
    "test_filename='test'\n",
    "\n",
    "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n",
    "test_filenamepath = os.path.abspath(os.path.join(DATA_PATH, test_filename))\n",
    "train_path = DATA_PATH\n",
    "test_path = DATA_PATH\n",
    "INPUT_COLUMN = 'input'\n",
    "TARGET_COLUMN = 'target'\n",
    "TARGET_FOR_INPUT = 'target_for_input'\n",
    "NUM_SAMPLES = 20000\n",
    "NUM_TEST_SAMPLES = 15\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 1024\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "ATTENTION_FUNC='general'\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Input Length:  52\n",
      "昨日 の 写真 の 男\n",
      "[365, 1, 258, 1, 152]\n",
      "Max Target Length:  44\n",
      "Found 15664 unique input tokens.\n",
      "Found 13529 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(train_filenamepath, sep=\"\\t\", header=None, names=[TARGET_COLUMN,INPUT_COLUMN], usecols=[0,1],\n",
    "               nrows=NUM_SAMPLES)\n",
    "test_df=pd.read_csv(test_filenamepath, sep=\"\\t\", header=None, names=[TARGET_COLUMN,INPUT_COLUMN], usecols=[0,1],\n",
    "               nrows=NUM_TEST_SAMPLES)\n",
    "\n",
    "import spacy\n",
    "spacy_japanese = spacy.load(\"ja_core_news_md\")\n",
    "def tokenize_japanese(text):\n",
    "    try:\n",
    "        listHold = [token.text for token in spacy_japanese.tokenizer(text)]\n",
    "        word = \" \".join(listHold)\n",
    "        return word\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "input_data=df[INPUT_COLUMN].apply(lambda x : tokenize_japanese(x)).tolist()\n",
    "target_data=df[TARGET_COLUMN].apply(lambda x : x + ' <eos>').tolist()\n",
    "target_input_data=df[TARGET_COLUMN].apply(lambda x : '<sos> '+ x).tolist()\n",
    "\n",
    "test_input_data=test_df[INPUT_COLUMN].apply(lambda x : tokenize_japanese(x)).tolist()\n",
    "test_target_data=test_df[TARGET_COLUMN].apply(lambda x : x + ' <eos>').tolist()\n",
    "test_target_input_data=test_df[TARGET_COLUMN].apply(lambda x : '<sos> '+ x).tolist()\n",
    "\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer_inputs.fit_on_texts(input_data)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
    "input_max_len = max(len(s) for s in input_sequences)\n",
    "print('Max Input Length: ', input_max_len)\n",
    "print(input_data[1000])\n",
    "print(input_sequences[1000])\n",
    "\n",
    "\n",
    "\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_data)\n",
    "tokenizer_outputs.fit_on_texts(target_input_data)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
    "target_max_len = max(len(s) for s in target_sequences)\n",
    "print('Max Target Length: ', target_max_len)\n",
    "\n",
    "\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "num_words_inputs = len(word2idx_inputs) + 1\n",
    "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "        embed = self.embedding(input_sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
    "                tf.zeros([batch_size, self.hidden_dim]))\n",
    "    \n",
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size, attention_func):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.attention_func = attention_func\n",
    "\n",
    "        if attention_func not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(\n",
    "                'Attention score must be either dot, general or concat.')\n",
    "\n",
    "        if attention_func == 'general':\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "\n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        if self.attention_func == 'dot':\n",
    "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
    "        elif self.attention_func == 'general':\n",
    "            score = tf.matmul(decoder_output, self.wa(\n",
    "                encoder_output), transpose_b=True)\n",
    "        elif self.attention_func == 'concat':\n",
    "            decoder_output = tf.tile(\n",
    "                decoder_output, [1, encoder_output.shape[1], 1])\n",
    "            score = self.va(\n",
    "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1)))\n",
    "\n",
    "            score = tf.transpose(score, [0, 2, 1])\n",
    "\n",
    "        alignment = tf.keras.activations.softmax(score, axis=-1)\n",
    "        \n",
    "        context = tf.matmul(alignment, encoder_output)\n",
    "\n",
    "        return context, alignment\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, attention_func):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.attention = LuongAttention(hidden_dim, attention_func)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            hidden_dim, return_sequences=True, return_state=True)\n",
    "        self.wc = tf.keras.layers.Dense(hidden_dim, activation='tanh')\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, input_sequence, state, encoder_output):\n",
    "        embed = self.embedding(input_sequence)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "\n",
    "        context, alignment = self.attention(lstm_out, encoder_output)\n",
    "\n",
    "        lstm_out = tf.concat(\n",
    "            [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "        logits = self.ws(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c, alignment\n",
    "    \n",
    "    \n",
    "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM, ATTENTION_FUNC)\n",
    "# initial_state = encoder.init_states(1)\n",
    "# encoder_outputs = encoder(tf.constant([[1]]), initial_state)\n",
    "# decoder_outputs = decoder(tf.constant(\n",
    "#     [[1]]), encoder_outputs[1:], encoder_outputs[0])\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "その 二人 の 先生 は 、 同じ 数 の 生徒 を 受け 持っ て い た 。\n",
      "and the same ones ive seen it influenced is my favorite power of the same <eos>\n",
      "source: ['その', '二人', 'の', '先生', 'は', '、', '同じ', '数', 'の', '生徒', 'を', '受け', '持っ', 'て', 'い', 'た', '。']\n",
      "prediction: ['and', 'the', 'same', 'ones', 'ive', 'seen', 'it', 'influenced', 'is', 'my', 'favorite', 'power', 'of', 'the', 'same', '<eos>']\n",
      "actual: The two teachers had an equal number of students. <eos>\n",
      "\n",
      "ウェイトレス は ジュース を 私 の 前 に 置い た 。\n",
      "i bought the pictures of the vending team on the cause i bought a threat of the physical <eos>\n",
      "source: ['ウェイトレス', 'は', 'ジュース', 'を', '私', 'の', '前', 'に', '置い', 'た', '。']\n",
      "prediction: ['i', 'bought', 'the', 'pictures', 'of', 'the', 'vending', 'team', 'on', 'the', 'cause', 'i', 'bought', 'a', 'threat', 'of', 'the', 'physical', '<eos>']\n",
      "actual: The waitress set a glass of juice in front of me. <eos>\n",
      "\n",
      "両者 の 間 に は 著しい 違い が ある 。\n",
      "of them not with systems <eos>\n",
      "source: ['両者', 'の', '間', 'に', 'は', '著しい', '違い', 'が', 'ある', '。']\n",
      "prediction: ['of', 'them', 'not', 'with', 'systems', '<eos>']\n",
      "actual: There are noticeable differences between the two. <eos>\n",
      "\n",
      "ちょっと 見 て いただき たい もの が ある ん です けど 。\n",
      "look at the place no far of me throwing tea <eos>\n",
      "source: ['ちょっと', '見', 'て', 'いただき', 'たい', 'もの', 'が', 'ある', 'ん', 'です', 'けど', '。']\n",
      "prediction: ['look', 'at', 'the', 'place', 'no', 'far', 'of', 'me', 'throwing', 'tea', '<eos>']\n",
      "actual: There's something I'd like you to take a look at. <eos>\n",
      "\n",
      "彼 ら は 私 たち の 居間 の ソファー に 座っ て い た 。\n",
      "they were just going to tell them weve made them <eos>\n",
      "source: ['彼', 'ら', 'は', '私', 'たち', 'の', '居間', 'の', 'ソファー', 'に', '座っ', 'て', 'い', 'た', '。']\n",
      "prediction: ['they', 'were', 'just', 'going', 'to', 'tell', 'them', 'weve', 'made', 'them', '<eos>']\n",
      "actual: They were sitting on the sofa in our living room. <eos>\n",
      "\n",
      "トム は 音楽 を 聞き ながら 勉強 する の が 好き だ 。\n",
      "i asked you to hear the angel to tom <eos>\n",
      "source: ['トム', 'は', '音楽', 'を', '聞き', 'ながら', '勉強', 'する', 'の', 'が', '好き', 'だ', '。']\n",
      "prediction: ['i', 'asked', 'you', 'to', 'hear', 'the', 'angel', 'to', 'tom', '<eos>']\n",
      "actual: Tom likes to listen to music while he's studying. <eos>\n",
      "\n",
      "パーティ で は 大いに 歌い 踊り まし た 。\n",
      "another attack school in the body where seed that any school <eos>\n",
      "source: ['パーティ', 'で', 'は', '大いに', '歌い', '踊り', 'まし', 'た', '。']\n",
      "prediction: ['another', 'attack', 'school', 'in', 'the', 'body', 'where', 'seed', 'that', 'any', 'school', '<eos>']\n",
      "actual: We did a lot of singing and dancing at the party. <eos>\n",
      "\n",
      "今 出発 すれ ば 飛行 機 に 間に合う でしょう か 。\n",
      "from run into times i wont think you should be out of here <eos>\n",
      "source: ['今', '出発', 'すれ', 'ば', '飛行', '機', 'に', '間に合う', 'でしょう', 'か', '。']\n",
      "prediction: ['from', 'run', 'into', 'times', 'i', 'wont', 'think', 'you', 'should', 'be', 'out', 'of', 'here', '<eos>']\n",
      "actual: Will we be in time for the plane if we leave now? <eos>\n",
      "\n",
      "両親 に 知れ たら 面倒 な こと に なる よ 。\n",
      "youve been working out of parents <eos>\n",
      "source: ['両親', 'に', '知れ', 'たら', '面倒', 'な', 'こと', 'に', 'なる', 'よ', '。']\n",
      "prediction: ['youve', 'been', 'working', 'out', 'of', 'parents', '<eos>']\n",
      "actual: You'll get into trouble if your parents find out. <eos>\n",
      "\n",
      "３ 人 組 が 白昼 その 銀行 を 襲っ た 。\n",
      "him two inches on the side of the road <eos>\n",
      "source: ['３', '人', '組', 'が', '白昼', 'その', '銀行', 'を', '襲っ', 'た', '。']\n",
      "prediction: ['him', 'two', 'inches', 'on', 'the', 'side', 'of', 'the', 'road', '<eos>']\n",
      "actual: A gang of three robbed the bank in broad daylight. <eos>\n",
      "\n",
      "この 本 は 読む たび に 発見 が ある\n",
      "so i was doing a book <eos>\n",
      "source: ['この', '本', 'は', '読む', 'たび', 'に', '発見', 'が', 'ある']\n",
      "prediction: ['so', 'i', 'was', 'doing', 'a', 'book', '<eos>']\n",
      "actual: Every time I read this book, I find something new. <eos>\n",
      "\n",
      "彼 は 会話 の 最中 に 口 を 挟む こと が よく ある 。\n",
      "we are just like that i cant start talking about some <eos>\n",
      "source: ['彼', 'は', '会話', 'の', '最中', 'に', '口', 'を', '挟む', 'こと', 'が', 'よく', 'ある', '。']\n",
      "prediction: ['we', 'are', 'just', 'like', 'that', 'i', 'cant', 'start', 'talking', 'about', 'some', '<eos>']\n",
      "actual: He often breaks into the middle of a conversation. <eos>\n",
      "\n",
      "その 言葉 久しぶり に 聞い た 気 が し ます 。\n",
      "you understand that the maggie said <eos>\n",
      "source: ['その', '言葉', '久しぶり', 'に', '聞い', 'た', '気', 'が', 'し', 'ます', '。']\n",
      "prediction: ['you', 'understand', 'that', 'the', 'maggie', 'said', '<eos>']\n",
      "actual: I don't think I've heard that word in a long time. <eos>\n",
      "\n",
      "私 に は 相談 する 友達 が たくさん いる 。\n",
      "i got the one you left the girl <eos>\n",
      "source: ['私', 'に', 'は', '相談', 'する', '友達', 'が', 'たくさん', 'いる', '。']\n",
      "prediction: ['i', 'got', 'the', 'one', 'you', 'left', 'the', 'girl', '<eos>']\n",
      "actual: I have a lot of friends I can discuss things with. <eos>\n",
      "\n",
      "午後 は ずっと 友人 と お しゃべり を し て 過ごし た 。\n",
      "after happiness from longshadows patent outside <eos>\n",
      "source: ['午後', 'は', 'ずっと', '友人', 'と', 'お', 'しゃべり', 'を', 'し', 'て', '過ごし', 'た', '。']\n",
      "prediction: ['after', 'happiness', 'from', 'longshadows', 'patent', 'outside', '<eos>']\n",
      "actual: I spent the whole afternoon chatting with friends. <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
    "checkpoint_dir = './training_ckpt_seq2seq_att'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "def predict_seq2seq_att(input_text, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
    "    if input_text is None:\n",
    "        input_text = input_data[np.random.choice(len(input_data))]\n",
    "    print(input_text)\n",
    "\n",
    "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
    "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    \n",
    "    out_words = []\n",
    "    alignments = []\n",
    "\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c, alignment = decoder(de_input, (de_state_h, de_state_c), en_outputs[0])\n",
    "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
    "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
    "        alignments.append(alignment.numpy())\n",
    "\n",
    "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
    "            break\n",
    "\n",
    "    print(' '.join(out_words))\n",
    "    return np.array(alignments), input_text.split(' '), out_words\n",
    "\n",
    "for i, test_sent in enumerate(test_input_data):\n",
    "    alignments, source, prediction = predict_seq2seq_att(test_sent, input_max_len, tokenizer_inputs, \n",
    "                                                     word2idx_outputs, idx2word_outputs)\n",
    "    print(\"source:\", source)\n",
    "    print(\"prediction:\", prediction)\n",
    "    print(\"actual:\", test_target_data[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
